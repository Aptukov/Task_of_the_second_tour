{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Исследовательский анализ данных"
      ],
      "metadata": {
        "id": "68SNDgS45LjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##На каких языках написаны статьи"
      ],
      "metadata": {
        "id": "Giu2r8kz5b5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Научные статьи могут быть написаны на различных языках, среди которых наиболее распространены:\n",
        "\n",
        "\n",
        "* Английский\n",
        "\n",
        "* Немецкий\n",
        "\n",
        "* Французский\n",
        "\n",
        "* Испанский\n",
        "\n",
        "* Португальский\n",
        "\n",
        "* Русский\n",
        "\n",
        "Английский язык является доминирующим, большинство статей публикуется именно на нем."
      ],
      "metadata": {
        "id": "SCnB7eOkpu2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Тематики статей"
      ],
      "metadata": {
        "id": "ACQgfihn6HBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тематики научных статей могут варьироваться в зависимости от области исследования. Вот несколько основных категорий:\n",
        "\n",
        "* Медицинские науки (фундаментальная медицина, биотехнологии в медицине)\n",
        "\n",
        "* Гуманитарные науки (история, археология, философия)\n",
        "\n",
        "* Естественные и точные науки (физика, химия, математика)\n",
        "\n",
        "* Социальные науки (психология, экономика, политология)\n",
        "\n",
        "* Инженерия и технологии (информационные технологии, машиностроение, энергетика)"
      ],
      "metadata": {
        "id": "4Z-gq3xCyONU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Проблемы в данных"
      ],
      "metadata": {
        "id": "V4cMp_j06MUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При анализе научных статей могут возникнуть следующие проблемы:\n",
        "\n",
        "* Устаревшие данные - статьи могут содержать нерелевантную и неактуальную информацию\n",
        "\n",
        "* Отсутствие единого формата - разные журналы и издательства могут иметь различные требования к структуре и оформлению статей, а также сами статьи могут быть различного формата (pdf, doc, txt)\n",
        "\n",
        "* Языковой барьер - статьи на разных языках могут быть сложными для анализа из-за различий в терминологии и написании\n",
        "\n",
        "* Дубликаты - в статьях могут содержаться дубликаты, что также искажает результаты анализа\n",
        "\n",
        "* Неполнота метаданных - отсутствие каких-либо данных в статье может негативно повлиять на анализ"
      ],
      "metadata": {
        "id": "XBnGv2_Q2Urz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Выбор метрик и их обоснование"
      ],
      "metadata": {
        "id": "yKY4aiVmf-T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rouge\n",
        "####Recall-Oriented Understudy for Gisting Evaluation"
      ],
      "metadata": {
        "id": "zKrPSH_1gCh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROUGE** — это набор метрик, который измеряет совпадения между резюме и оригинальным текстом. Он включает в себя:\n",
        "\n",
        "* ROUGE-N (частота последовательности из N слов)\n",
        " * Rouge-1 (сравнивает однословные последовательности)\n",
        " * Rouge-2 (сравнивает двухсловные последовательности)\n",
        "\n",
        "* ROUGE-L (сравнивает самые длинные общие подпоследовательности слов)"
      ],
      "metadata": {
        "id": "VAe8Z33l5NKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BERTScore"
      ],
      "metadata": {
        "id": "vJv8k08ZgIb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERTScore** - использует предобученную модель BERT для оценки смыслового сходства резюме и исходного текста. Эта метрчка включает в себя:\n",
        "* Precision (Точность) - сколько правильных ответов среди всех выданных ответов\n",
        "* Recall (Полнота) - показывает долю правильных ответов\n",
        "* F-score - среднее гармоническое между precision и recall"
      ],
      "metadata": {
        "id": "6svnmPdA7Soz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Анализ моделей для резюмирования статей"
      ],
      "metadata": {
        "id": "8F-7In6a6Uew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Установка библиотек"
      ],
      "metadata": {
        "id": "ePqpk2tbpipJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas gigachain-community transformers torch rouge bert-score datasets"
      ],
      "metadata": {
        "id": "k2-eTT6Mgyxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcde4c40-239d-4fda-b6c4-39a69dc02e6e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: gigachain-community in /usr/local/lib/python3.10/dist-packages (0.2.16.post3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (0.6.7)\n",
            "Requirement already satisfied: gigachain<0.3.0,>=0.2.16 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (0.2.16)\n",
            "Requirement already satisfied: gigachain-core<0.3.0,>=0.2.38post2 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (0.2.38.post2)\n",
            "Requirement already satisfied: gigachat>=0.1.35 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (0.1.35)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (0.1.137)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from gigachain-community) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->gigachain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->gigachain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->gigachain-community) (0.9.0)\n",
            "Requirement already satisfied: gigachain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from gigachain<0.3.0,>=0.2.16->gigachain-community) (0.2.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from gigachain<0.3.0,>=0.2.16->gigachain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from gigachain-core<0.3.0,>=0.2.38post2->gigachain-community) (1.33)\n",
            "Requirement already satisfied: langfuse<3.0.0,>=2.41.0 in /usr/local/lib/python3.10/dist-packages (from gigachain-core<0.3.0,>=0.2.38post2->gigachain-community) (2.53.3)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.10/dist-packages (from gigachat>=0.1.35->gigachain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->gigachain-community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->gigachain-community) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->gigachain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->gigachain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->gigachain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->gigachain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->gigachain-community) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1->gigachat>=0.1.35->gigachain-community) (4.6.2.post1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1->gigachat>=0.1.35->gigachain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1->gigachat>=0.1.35->gigachain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1->gigachat>=0.1.35->gigachain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->gigachain-core<0.3.0,>=0.2.38post2->gigachain-community) (3.0.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langfuse<3.0.0,>=2.41.0->gigachain-core<0.3.0,>=0.2.38post2->gigachain-community) (2.2.1)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.10/dist-packages (from langfuse<3.0.0,>=2.41.0->gigachain-core<0.3.0,>=0.2.38post2->gigachain-community) (1.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->gigachain<0.3.0,>=0.2.16->gigachain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->gigachain<0.3.0,>=0.2.16->gigachain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->gigachain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->gigachain-community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1->gigachat>=0.1.35->gigachain-community) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Импортирование библиотек"
      ],
      "metadata": {
        "id": "r4eaGLjPpZH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain_community.chat_models.gigachat import GigaChat\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch"
      ],
      "metadata": {
        "id": "o11fsAvgpYBB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Загрузка данных"
      ],
      "metadata": {
        "id": "8i3U4s3Wp8iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Загрузка датасета PubMed\n",
        "ds = load_dataset(\"ccdv/pubmed-summarization\", \"section\")\n",
        "\n",
        "# Преобразование в pandas DataFrame\n",
        "df = ds['train'].to_pandas()[:100]\n",
        "# Так как на весь массив данных бесплатных токенов GigaChat не хватит, используем лишь первые 100 строк \n",
        "# В дальнейшем, планируется, что финансовые возможности позволят использовать GigaChat, не испытывая нехватку токенов\n",
        "\n",
        "# Просмотр первых нескольких строк DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "Kaqt4klVp_7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b808e3-2808-4e71-bb54-7db2311c060f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             article  \\\n",
            "0  a recent systematic analysis showed that in 20...   \n",
            "1  it occurs in more than 50% of patients and may...   \n",
            "2  tardive dystonia ( td ) , a rarer side effect ...   \n",
            "3  lepidoptera include agricultural pests that , ...   \n",
            "4  syncope is caused by transient diffuse cerebra...   \n",
            "\n",
            "                                            abstract  \n",
            "0  background : the present study was carried out...  \n",
            "1  backgroundanemia in patients with cancer who a...  \n",
            "2  tardive dystonia ( td ) is a serious side effe...  \n",
            "3  many lepidopteran insects are agricultural pes...  \n",
            "4  we present an unusual case of recurrent cough ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Резюмируем статьи с помощью моделей T5 и GigaChat"
      ],
      "metadata": {
        "id": "LZi8MZpR-kOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запрашиваем ключ авторизации GigaChat API"
      ],
      "metadata": {
        "id": "P2k8kWFi-eJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Authorization_key = input()"
      ],
      "metadata": {
        "id": "Hw3GYMYH-dgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962edefd-f3b4-4c98-d106-a1629c8fbef7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ZTc0NTdhMjYtYjk5OC00MzE3LTllMzYtMjNkNGU2ZGY2NTRjOmEwZWZlNzRjLTAxYzUtNGQ5ZS1hNjllLWEyMTcwODJmZWMyMQ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем модели T5 и GigaChat"
      ],
      "metadata": {
        "id": "fXn4ysWN-tH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели T5\n",
        "t5_model_name = 't5-large'\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
        "\n",
        "# Инициализация модели GigaChat\n",
        "chat = GigaChat(credentials=Authorization_key, scope='GIGACHAT_API_PERS', model='GigaChat', streaming=True, verify_ssl_certs=False)"
      ],
      "metadata": {
        "id": "jUMahY2qDxUH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание столбца с резюме при помощи GigaChat"
      ],
      "metadata": {
        "id": "QJ_Xc7WsTFwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации резюме с помощью GigaChat\n",
        "def summarize_with_gigachat(article):\n",
        "    messages = [\n",
        "                SystemMessage(content=\"You are an assistant for summarizing the text. Write an answer, depending on the language of the article itself. Use from 100 to 250 words and be laconic in the answer.\"),\n",
        "                HumanMessage(content=article)\n",
        "            ]\n",
        "    return chat(messages).content\n",
        "\n",
        "# Генерация резюме для GigaChat\n",
        "df['gigachat_summary'] = df['article'].apply(summarize_with_gigachat)"
      ],
      "metadata": {
        "id": "UuDuUpG-TP07"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание столбца с резюме при помощи T5"
      ],
      "metadata": {
        "id": "Vj-IPYq-eHMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации резюме с помощью T5\n",
        "def summarize_with_t5(article):\n",
        "    inputs = t5_tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = t5_model.generate(inputs, max_length=250, min_length=100, early_stopping=True)\n",
        "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Генерация резюме для T5\n",
        "df['t5_summary'] = df['article'].apply(summarize_with_t5)"
      ],
      "metadata": {
        "id": "osoxQtuBeE7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6e5789-1991-48f5-9fa6-6fb96e3f0468"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка качества резюме и работы моделей"
      ],
      "metadata": {
        "id": "77Ie3GqzTR3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортирование метрик\n",
        "from rouge import Rouge\n",
        "from bert_score import score\n",
        "\n",
        "# Создание списка с аннотациями для метрики Bert score\n",
        "references = df['abstract'].tolist()\n",
        "\n",
        "# Подсчет метрик\n",
        "\n",
        "# BERTScore\n",
        "bert_scores_gigachat = []\n",
        "bert_scores_t5 = []\n",
        "for i in range(len(df['abstract'])):\n",
        "    score_result_gigachat = score([df['gigachat_summary'][i]], [references[i]], lang='en')\n",
        "    score_result_t5 = score([df['t5_summary'][i]], [references[i]], lang='en')\n",
        "    bert_scores_gigachat.append(score_result_gigachat)\n",
        "    bert_scores_t5.append(score_result_t5)\n",
        "\n",
        "# Rouge-L score\n",
        "rouge_l_scores_gigachat = []\n",
        "rouge_l_scores_t5 = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    reference_summary = row['abstract']\n",
        "    rouge = Rouge()\n",
        "\n",
        "    # GigaChat\n",
        "    predicted_summary_gigachat = row['gigachat_summary']\n",
        "    rouge_scores_gigachat = rouge.get_scores(predicted_summary_gigachat, reference_summary, avg=True)\n",
        "    rouge_l_scores_gigachat.append(rouge_scores_gigachat['rouge-l']['f'])\n",
        "\n",
        "    # T5\n",
        "    predicted_summary_t5 = row['t5_summary']\n",
        "    rouge_scores_t5 = rouge.get_scores(predicted_summary_t5, reference_summary, avg=True)\n",
        "    rouge_l_scores_t5.append(rouge_scores_t5['rouge-l']['f'])\n",
        "\n",
        "# Вычисление среднего значения метрик для GigaChat\n",
        "rouge_l_gigachat = sum(rouge_l_scores_gigachat) / len(rouge_l_scores_gigachat)\n",
        "bert_score_gigachat = sum([score[2].item() for score in bert_scores_gigachat]) / len(bert_scores_gigachat)\n",
        "\n",
        "# Вычисление среднего значения метрик для T5\n",
        "rouge_l_t5 = sum(rouge_l_scores_t5) / len(rouge_l_scores_t5)\n",
        "bert_score_t5 = sum([score[2].item() for score in bert_scores_t5]) / len(bert_scores_t5)\n",
        "\n",
        "# Выводим результаты метрик для GigaChat\n",
        "print(\"Результаты GigaChat\")\n",
        "print(\"Метрика Rouge-L\", rouge_l_gigachat) # 0,24\n",
        "print(\"Метрика Bert score:\", bert_score_gigachat) # 0,84\n",
        "\n",
        "# Выводим результаты метрик для T5\n",
        "print(\"Результаты T5\")\n",
        "print(\"Метрика Rouge-L\", rouge_l_t5) # 0,22\n",
        "print(\"Метрика Bert score:\", bert_score_t5) # 0,82"
      ],
      "metadata": {
        "id": "_lXo8L68tuzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c525e47-8b98-45d7-8172-b510d22be113"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты GigaChat\n",
            "Метрика Rouge-L 0.24150578422009317\n",
            "Метрика Bert score: 0.8408654729525248\n",
            "Результаты T5\n",
            "Метрика Rouge-L 0.2218384973377089\n",
            "Метрика Bert score: 0.8247800568739573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Вывод"
      ],
      "metadata": {
        "id": "P5SUuQGOuRQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По показателям Rouge-L и BERTScore модель GigaChat лучше, чем T5, также стоит учитывать, что при работе на русском языке, результаты модели GigaChat станут ещё выше"
      ],
      "metadata": {
        "id": "NyZUSkqfyFjD"
      }
    }
  ]
}
